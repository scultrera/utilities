{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa3ef9-c292-4900-ab85-86cbfb8bda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To Replicate idea from this paper, https://arxiv.org/pdf/1905.04348.pdf: \n",
    "    Multiclass Language Identification using Deep Learning on Spectral Images of Audio Signals\n",
    "Found this dataset:\n",
    "    Kaggle Spoken Language Identification (https://www.kaggle.com/toponowicz/spoken-language-identification)\n",
    "Borrowed some code form our Community Git to convert audio to spectrograms:\n",
    "    https://github.com/datarobot-community/tutorials-for-data-scientists/blob/master/VisualAI/Python/VisualAI%20Heartbeats/heartbeat_visual_AI.ipynb\n",
    "\n",
    "Steve Cultrera, 1/7/2022\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318b1a77-db3d-4a2d-9d04-e40d8d6beb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7a6cb52a-c227-4b07-aa66-f65f0f40876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from random import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "016fff92-bda5-4706-a2ba-aaef7bdb8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioConf:\n",
    "    # Preprocessing settings\n",
    "    sampling_rate = 44100\n",
    "    window_function = 'hanning'\n",
    "    hop_length_percentage = 0.25 # determines the amount of overlap, higher means more frames\n",
    "    window_length = 2048  # length of the FFT window\n",
    "    hop_length = int(window_length * hop_length_percentage)  # number of samples between successive frames.\n",
    "        \n",
    "\n",
    "def scale_minmax(X, min=0.0, max=255.0):\n",
    "    \"\"\" rescaling from dB to image pixel values from 0 to 255\n",
    "    \"\"\"\n",
    "    X_std = (X - X.min()) / (X.max() - X.min())\n",
    "    X_scaled = X_std * (max - min) + min\n",
    "    return X_scaled.astype(np.uint8)\n",
    "\n",
    "\n",
    "def raw_audio_frames_to_logmelspectrogram(raw_audio, conf):\n",
    "    melspectrogram = librosa.feature.melspectrogram(\n",
    "        raw_audio,\n",
    "        sr=conf.sampling_rate,\n",
    "        hop_length=conf.hop_length,\n",
    "        n_fft=conf.window_length,\n",
    "        window=conf.window_function,\n",
    "    )\n",
    "\n",
    "    logmelspectrogram = librosa.power_to_db(melspectrogram)\n",
    "    logmelspectrogram = scale_minmax(logmelspectrogram).astype('uint8')\n",
    "    cmap = plt.get_cmap('magma')\n",
    "    rgba_logmelspectrogram = cmap(logmelspectrogram)\n",
    "    rgb_logmelspectrogram = (np.delete(rgba_logmelspectrogram, 3, 2) * 255).astype('uint8')\n",
    "    return rgb_logmelspectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0441628c-c640-406e-ab70-860543d8f8a6",
   "metadata": {},
   "source": [
    "## Just some tests to get one file working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "627423ce-a091-47ba-be41-90e57eada9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"/Users/steve.cultrera/Documents/kaggle_spoken_language_identification\"\n",
    "\n",
    "one_file = os.path.join(project_dir, \"archive/train/train\", \"de_f_5d2e7f30d69f2d1d86fd05f3bbe120c2.fragment1.flac\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cc7b72c-2a71-4430-93c4-5654f276d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(one_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34397eaf-9fa3-4652-ae87-8c5a2a62efd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7196ccc0-049e-4e20-b6dd-d563e036e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "logmelspectrogram = raw_audio_frames_to_logmelspectrogram(y, AudioConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b2d7760-0ca0-4763-bd02-cdebaa440d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pillow_image = Image.fromarray(logmelspectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2daf313-9feb-4317-9603-83f04a88b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pillow_image.save(\"test.png\", \"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8d93a9e-d0b9-4640-87dd-5b5c39980c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431, 128)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pillow_image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c40a87c-b110-4ba5-9e4a-20d140525410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50176 55168\n"
     ]
    }
   ],
   "source": [
    "# files aren't that much bigger than max\n",
    "print(224*224, 431*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2b1e620d-1e75-4f22-8e8a-4b3063e4c187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37984711672670657\n"
     ]
    }
   ],
   "source": [
    "print(random())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d6017-e0dc-456d-99b6-5cc0c1bc393d",
   "metadata": {},
   "source": [
    "## Process an entire directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ea660034-4eb0-488e-8e08-bdf270fc5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Toggled between this two...\n",
    "\n",
    "#-- all the files from train came to ~7GB, so let's halve that:\n",
    "#input_DIR = os.path.join(project_dir, \"archive/train/train\")\n",
    "#sample_rate = 0.5\n",
    "\n",
    "input_DIR = os.path.join(project_dir, \"archive/test/test\")\n",
    "sample_rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0396e58a-681d-42b4-9d89-e6c3d32cbb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = os.path.join(project_dir, \"kaggle_sli_data\", \"kaggle_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b8d3ced-89af-43f9-bc9b-d0d291aa4841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/steve.cultrera/Documents/kaggle_spoken_language_identification/archive/test/test'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "763e64c0-239e-4851-9ceb-39a9a0dc90cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(output_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"language\", \"gender\", \"file_id\", \"image\"])\n",
    "    \n",
    "    for filename in os.listdir(input_DIR):\n",
    "        \n",
    "        if filename.endswith(\".flac\") and random() <= sample_rate:\n",
    "            language = filename[:2]\n",
    "            gender = filename[3:4]\n",
    "            file_id = filename[5:]\n",
    "            #print(filename)\n",
    "            #print(language, gender, file_id)\n",
    "            \n",
    "            \n",
    "            #-- generate the image \n",
    "            y, sr = librosa.load(os.path.join(input_DIR, filename))\n",
    "            logmelspectrogram = raw_audio_frames_to_logmelspectrogram(y, AudioConf)\n",
    "            pillow_image = Image.fromarray(logmelspectrogram)\n",
    "            output_image_filename = file_id + \".png\"\n",
    "            pillow_image.save(os.path.join(project_dir, \"kaggle_sli_data\", \"image\", output_image_filename))\n",
    "            \n",
    "            #-- finally, write the row to csv now that we have everything\n",
    "            writer.writerow([language, gender, file_id, \"image/\" + output_image_filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb08fc84-d25a-487e-be8a-d27aaf8bd26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/steve.cultrera/Documents/kaggle_spoken_language_identification/kaggle_sli_data_TEST.zip'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- make zipped file which can be imported into platform\n",
    "shutil.make_archive(\"kaggle_sli_data_TEST\", 'zip', os.path.join(project_dir, \"kaggle_sli_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d42082-8c2b-42a6-8e07-f04d561538c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
